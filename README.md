# YouTube AI Analytics
Final project: Data Engineering Zoomcamp 2024 (by DataTalksClub).

Still working on this documentation, thanks for your patience! ðŸ˜„

# Current Dashboard

![Dashboard Page 1](/assets/looker-studio-1.png)
<!-- ![Dashboard Page 2](/assets/looker-studio-2.png) -->
![Dashboard Page 3](/assets/looker-studio-3.png)
![Dashboard Page 4](/assets/looker-studio-4.png)
![Dashboard Page 5](/assets/looker-studio-5.png)
![Dashboard Page 6](/assets/looker-studio-6.png)

# Instructions

## My Local Dev Setup
- **Operating systems:** Windows 11 + WSL (Ubuntu 22.04)
- **Version control system:** Git + GitHub, create account, setup SSH, clone this repository
- **Git folder:** Go to your projects folder (example "git") ```cd git```
- **Git clone:** ```git clone git@github.com:techwithcosta/youtube-ai-analytics.git```
- **Go into the project folder:** ```cd youtube-ai-analytics```
- **Some steps here:** [TechWithCosta: Data Engineering Zoomcamp](https://www.youtube.com/playlist?list=PLtU3RENZyLgoe-ptQhZy_mDgdZOMlTLNt)
- **IDE:** VSCode, install it on Windows
- **(Optional) Python:** Miniconda, install it on Ubuntu to run Python environments and isolate packages
- **Run VSCode from there:** ```code .```
- **Docker:** install Docker Desktop and set it up with WSL2, make sure it is running
- Run ```docker compose build``` from ```mage/``` folder
- Run ```docker compose up``` from ```mage/``` folder
- **Run orchestrator:** Open browser and Mage http://localhost:6789/
- **Pipeline scheduling:** Running weekly, each Sunday at 4am
- **Cloud:** GCP (setup trial if possible)
- from the project root folder execute ```chmod +x setup.sh && ./setup.sh```
- on ```terraform/keys/``` and ```mage/keys/``` update ```my-creds.json``` with GCP service account
- Enable YouTube Data API v3 on GCP to get API key
- Get OpenAI API key from OpenAI account (free or paid)
- on ```mage/``` update ```.env``` with both YouTube API and OpenAI API keys
- ```config.py``` contains all pipeline inputs, adjust if needed
- **Terraform (IaC):** install Terraform on Ubuntu, then adjust ```variables.tf``` from ```terraform/```, run ```terraform plan```, ```terraform apply``` and ```terraform destroy``` (if required)
- **Current Dashboard on Looker Studio:** [YouTube AI Analytics Dashboard](https://lookerstudio.google.com/reporting/6745d3eb-f9dd-4329-8d92-ecf8bd177e4d)

## Architecture Components
- **Cloud Provider:** Google Cloud Platform (GCP)
- **Infrastructure as Code (IaC):** Terraform
- **Containerization:** Docker
- **Orchestrator:** Mage
- **Data Transformations:** Python + SQL
- **Data Lake:** Google Cloud Storage
- **Data Warehouse:** BigQuery
- **Data Visualization:** Looker Studio

![Pipeline Trigger](/assets/pipeline-trigger-1.png)
![Pipeline Scheduling](/assets/pipeline-trigger-2.png)

## Notes
- Store inputs in same place (config.py)
- Data phases (raw, clean, enriched) YouTube API
- Channels, videos, comments
- AI analysis OpenAI API

## TODO
- Deploy Mage to cloud (GCP VM)
- Add trigger to run pipeline weekly
- Partitioning and clustering
- Get comment replies (currently getting top level comment only)
- Differentiate between regular video and short (specify on inputs what to get) (currently getting both)
- Implement categories to replace integers on df_videos by category string descriptions (youtube.videoCategories())
- Optimize videos API call from single video to batch ids
- Incremental loading
- Environments: Dev, Test, Prod (reflected on Terraform templates)
- Reproducibility: Dockerfile, docker-compose file


# README example to improve current

<div>
<img src="https://github.com/mage-ai/assets/blob/main/mascots/mascots-shorter.jpeg?raw=true">
</div>

## Data Engineering Zoomcamp - Week 2

Welcome to DE Zoomcamp with Mage! 

Mage is an open-source, hybrid framework for transforming and integrating data. âœ¨

In this module, you'll learn how to use the Mage platform to author and share _magical_ data pipelines. This will all be covered in the course, but if you'd like to learn a bit more about Mage, check out our docs [here](https://docs.mage.ai/introduction/overview). 

[Get Started](https://github.com/mage-ai/mage-zoomcamp?tab=readme-ov-file#lets-get-started)
[Assistance](https://github.com/mage-ai/mage-zoomcamp?tab=readme-ov-file#assistance)

## Let's get started

This repo contains a Docker Compose template for getting started with a new Mage project. It requires Docker to be installed locally. If Docker is not installed, please follow the instructions [here](https://docs.docker.com/get-docker/). 

You can start by cloning the repo:

```bash
git clone https://github.com/mage-ai/mage-zoomcamp.git mage-zoomcamp
```

Navigate to the repo:

```bash
cd mage-data-engineering-zoomcamp
```

Rename `dev.env` to simply `.env`â€” this will _ensure_ the file is not committed to Git by accident, since it _will_ contain credentials in the future.

Now, let's build the container

```bash
docker compose build
```

Finally, start the Docker container:

```bash
docker compose up
```

Now, navigate to http://localhost:6789 in your browser! Voila! You're ready to get started with the course. 

### What just happened?

We just initialized a new mage repository. It will be present in your project under the name `magic-zoomcamp`. If you changed the varable `PROJECT_NAME` in the `.env` file, it will be named whatever you set it to.

This repository should have the following structure:

```
.
â”œâ”€â”€ mage_data
â”‚   â””â”€â”€ magic-zoomcamp
â”œâ”€â”€ magic-zoomcamp
â”‚   â”œâ”€â”€ __pycache__
â”‚   â”œâ”€â”€ charts
â”‚   â”œâ”€â”€ custom
â”‚   â”œâ”€â”€ data_exporters
â”‚   â”œâ”€â”€ data_loaders
â”‚   â”œâ”€â”€ dbt
â”‚   â”œâ”€â”€ extensions
â”‚   â”œâ”€â”€ interactions
â”‚   â”œâ”€â”€ pipelines
â”‚   â”œâ”€â”€ scratchpads
â”‚   â”œâ”€â”€ transformers
â”‚   â”œâ”€â”€ utils
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ io_config.yaml
â”‚   â”œâ”€â”€ metadata.yaml
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ dev.env
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ requirements.txt
```

## Assistance

1. [Mage Docs](https://docs.mage.ai/introduction/overview): a good place to understand Mage functionality or concepts.
2. [Mage Slack](https://www.mage.ai/chat): a good place to ask questions or get help from the Mage team.
3. [DTC Zoomcamp](https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/week_2_workflow_orchestration): a good place to get help from the community on course-specific inquireies.
4. [Mage GitHub](https://github.com/mage-ai/mage-ai): a good place to open issues or feature requests.
